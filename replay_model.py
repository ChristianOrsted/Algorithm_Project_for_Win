import os
import warnings
import torch
import numpy as np
import time
from weak_tie_env import WeakTieStarCraft2Env
from weak_tie_agent import WeakTieAgent
from weak_tie_module import WeakTieGraph

# è¿‡æ»¤è­¦å‘Šå¹¶è®¾ç½® SC2 è·¯å¾„
warnings.filterwarnings('ignore', category=FutureWarning)
os.environ["SC2PATH"] = "C:\Program Files (x86)\StarCraft II"


def watch_agent_play(model_path, map_name="1c3s5z", n_episodes=3, step_delay=0.5):
    """
    å¯è§†åŒ–è§‚çœ‹æ™ºèƒ½ä½“å¯¹å±€
    :param model_path: æ¨¡å‹è·¯å¾„
    :param map_name: åœ°å›¾åç§°
    :param n_episodes: è§‚çœ‹å±€æ•°
    :param step_delay: æ¯æ­¥ä¹‹é—´çš„å»¶è¿Ÿï¼ˆç§’ï¼‰ï¼Œè°ƒæ•´è¿™ä¸ªå€¼æ¥æ§åˆ¶é€Ÿåº¦
    """
    # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(model_path):
        print(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
        return

    print(f"æ­£åœ¨åŠ è½½ç¯å¢ƒ: {map_name} ...")
    print(f"æ¯æ­¥å»¶è¿Ÿ: {step_delay}ç§’ (å¯åœ¨ä»£ç ä¸­è°ƒæ•´)")
    
    try:
        # åˆ›å»ºç¯å¢ƒï¼Œæ³¨æ„è¦å¯ç”¨æ¸²æŸ“
        env = WeakTieStarCraft2Env(map_name=map_name)
    except Exception as e:
        print(f"ç¯å¢ƒåˆ›å»ºå¤±è´¥: {e}")
        return

    env_info = env.get_env_info()
    n_agents = env_info["n_agents"]
    obs_dim = env_info["obs_shape"]
    n_actions = env_info["n_actions"]

    # å‚æ•°é…ç½® (ä¸è®­ç»ƒä¿æŒä¸€è‡´)
    if map_name in ["1c3s5z", "50m", "10m_vs_11m"]:
        HIDDEN_DIM = 256
    else:
        HIDDEN_DIM = 128

    print(f"åˆå§‹åŒ– Agent (Hidden Dim: {HIDDEN_DIM})...")

    # åˆå§‹åŒ– Agent
    agent = WeakTieAgent(
        n_agents=n_agents,
        obs_dim=obs_dim,
        act_dim=n_actions,
        hidden_dim=HIDDEN_DIM,
        lr=0.0003,
        gamma=0.99
    )

    # åŠ è½½æ¨¡å‹æƒé‡
    start_ep = agent.load_model(model_path)
    print(f"æ¨¡å‹åŠ è½½å®Œæˆ (è®­ç»ƒè½®æ•°: {start_ep})")

    # åˆå§‹åŒ–å¼±è”ç³»å›¾
    wt_graph = WeakTieGraph(n_agents, obs_range=15.0, alpha_quantile=0.3)

    print(f"\n{'='*60}")
    print(f"å¼€å§‹è§‚çœ‹ {n_episodes} å±€å¯¹å±€...")
    print(f"{'='*60}\n")

    with torch.no_grad():
        for ep in range(n_episodes):
            print(f"\n{'â”€'*60}")
            print(f"ç¬¬ {ep + 1}/{n_episodes} å±€")
            print(f"{'â”€'*60}")
            
            obs, state = env.reset()
            terminated = False
            episode_reward = 0
            
            # åˆå§‹åŒ– RNN éšè—çŠ¶æ€
            actor_hidden = agent.init_hidden(batch_size=1)
            
            step = 0
            while not terminated:
                step += 1
                
                # è·å–ç¯å¢ƒä¿¡æ¯
                avail_actions = env.get_avail_actions()
                positions = env.get_all_unit_positions()
                
                # è·å–å­˜æ´»çŠ¶æ€
                alive_mask = np.array([1 if env.agents[i].health > 0 else 0 for i in range(n_agents)])
                alive_count = np.sum(alive_mask)
                
                # è®¡ç®—å›¾ç»“æ„
                mask_beta, key_agent_idx = wt_graph.compute_graph_info(positions, alive_mask)
                
                # å†³ç­–ï¼ˆä½¿ç”¨ç¡®å®šæ€§ç­–ç•¥ï¼‰
                actions, probs, actor_hidden = agent.select_action(
                    obs, avail_actions, mask_beta, key_agent_idx, actor_hidden,
                    deterministic=True
                )
                
                # æ‰“å°è¯¦ç»†ä¿¡æ¯
                print(f"\nğŸ“ æ­¥æ•°: {step}")
                print(f"   å­˜æ´»å•ä½: {alive_count}/{n_agents}")
                print(f"   å…³é”®æ™ºèƒ½ä½“: Agent {key_agent_idx}")
                
                # æ‰“å°æ¯ä¸ªæ™ºèƒ½ä½“çš„åŠ¨ä½œå’Œæ¦‚ç‡
                action_names = ["No-op", "åœæ­¢", "å‘åŒ—", "å‘å—", "å‘ä¸œ", "å‘è¥¿", 
                               "æ”»å‡»æ•Œäºº..."]  # æ ¹æ®å®é™…åŠ¨ä½œé›†è°ƒæ•´
                print(f"   åŠ¨ä½œå†³ç­–:")
                for i in range(n_agents):
                    if alive_mask[i] == 0:
                        print(f"      Agent {i}: [å·²é˜µäº¡]")
                    else:
                        act = actions[i]
                        prob = probs[i][act] if probs is not None else 0.0
                        act_name = action_names[act] if act < len(action_names) else f"Action {act}"
                        print(f"      Agent {i}: {act_name} (ç½®ä¿¡åº¦: {prob:.2%})")
                
                # ç¯å¢ƒæ­¥è¿›
                reward, terminated, info = env.step(actions)
                obs = env.get_obs()
                episode_reward += reward
                
                print(f"   æœ¬æ­¥å¥–åŠ±: {reward:.2f}")
                
                # å»¶è¿Ÿï¼Œè®©ä½ èƒ½çœ‹æ¸…æ¥š
                time.sleep(step_delay)
                
                # é˜²æ­¢æ­»å¾ªç¯
                if step > 500:
                    print("\nè¾¾åˆ°æœ€å¤§æ­¥æ•°é™åˆ¶ï¼Œå¼ºåˆ¶ç»“æŸ")
                    terminated = True
            
            # ç»Ÿè®¡ç»“æœ
            is_win = info.get('battle_won', False)
            result_emoji = "èƒœåˆ©" if is_win else "âŒ å¤±è´¥"
            
            print(f"\n{'='*60}")
            print(f"ç¬¬ {ep + 1} å±€ç»“æœ: {result_emoji}")
            print(f"   æ€»å¥–åŠ±: {episode_reward:.2f}")
            print(f"   æ€»æ­¥æ•°: {step}")
            print(f"{'='*60}\n")
            
            if ep < n_episodes - 1:
                print("â³ å‡†å¤‡ä¸‹ä¸€å±€...\n")
                time.sleep(2)  # å±€é—´æš‚åœ2ç§’

    env.close()
    print(f"\nè§‚çœ‹å®Œæˆï¼")


if __name__ == "__main__":
    print("\n" + "="*60)
    print("æ™ºèƒ½ä½“å¯¹å±€å¯è§†åŒ–å·¥å…·")
    print("="*60)
    
    # é…ç½®å‚æ•°
    MODEL_PATH = "best_model.pt"  # æ¨¡å‹è·¯å¾„
    MAP_NAME = "1c3s5z"           # åœ°å›¾åç§°
    N_EPISODES = 3                # è§‚çœ‹å±€æ•°
    STEP_DELAY = 0.5              # æ¯æ­¥å»¶è¿Ÿï¼ˆç§’ï¼‰
    
    # ä½ å¯ä»¥è°ƒæ•´è¿™äº›å‚æ•°ï¼š
    # STEP_DELAY = 0.3  # æ›´å¿«
    # STEP_DELAY = 1.0  # æ›´æ…¢ï¼Œçœ‹å¾—æ›´æ¸…æ¥š
    # STEP_DELAY = 0.1  # å¿«é€Ÿæµè§ˆ
    
    print(f"\né…ç½®:")
    print(f"   æ¨¡å‹: {MODEL_PATH}")
    print(f"   åœ°å›¾: {MAP_NAME}")
    print(f"   å±€æ•°: {N_EPISODES}")
    print(f"   é€Ÿåº¦: æ¯æ­¥ {STEP_DELAY} ç§’")
    print(f"\næç¤º: å¯ä»¥åœ¨ä»£ç ä¸­è°ƒæ•´ STEP_DELAY æ¥æ”¹å˜è§‚çœ‹é€Ÿåº¦")
    print(f"   - 0.1-0.3: å¿«é€Ÿæµè§ˆ")
    print(f"   - 0.5-0.8: æ­£å¸¸è§‚çœ‹")
    print(f"   - 1.0-2.0: æ…¢é€Ÿåˆ†æ")
    print()
    
    # å¼€å§‹è§‚çœ‹
    watch_agent_play(
        model_path=MODEL_PATH,
        map_name=MAP_NAME,
        n_episodes=N_EPISODES,
        step_delay=STEP_DELAY
    )
